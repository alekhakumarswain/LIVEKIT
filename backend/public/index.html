<!DOCTYPE html>
<html>

<head>
    <title>Voice Agent Orchestration</title>
    <style>
        body {
            font-family: system-ui, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f4f4f4;
        }

        .card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }

        h2 {
            margin-top: 0;
        }

        .grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }

        button {
            padding: 10px 15px;
            cursor: pointer;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
        }

        button:disabled {
            background: #ccc;
        }

        button.red {
            background: #dc3545;
        }

        textarea {
            width: 100%;
            height: 100px;
            padding: 8px;
            margin-bottom: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }

        #log {
            height: 200px;
            overflow-y: auto;
            background: #222;
            color: #0f0;
            padding: 10px;
            font-family: monospace;
            border-radius: 4px;
        }

        .status-badge {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: bold;
            background: #eee;
        }

        .status-badge.connected {
            background: #d4edda;
            color: #155724;
        }
    </style>
</head>

<body>
    <h1>ü§ñ Real-Time Voice Agent</h1>

    <div class="grid">
        <!-- Core Controls -->
        <div class="card">
            <h2>üìû Call Controls</h2>
            <div style="margin-bottom: 10px;">
                Status: <span id="connectionStatus" class="status-badge">Disconnected</span>
            </div>
            <button id="connectBtn">Start Call</button>
            <button id="disconnectBtn" class="red" disabled>End Call</button>
        </div>

        <!-- Knowledge Base -->
        <div class="card">
            <h2>üìö Knowledge Base (RAG)</h2>
            <p style="font-size: 0.9em; color: #666;">Upload .txt files to ingest context.</p>
            <input type="file" id="kbUpload" accept=".txt,.md">
            <button id="uploadBtn" style="margin-top: 10px;" disabled>Ingest Document</button>
            <div id="uploadStatus" style="margin-top: 5px; font-size: 0.8em;"></div>
        </div>
    </div>

    <!-- Agent Config -->
    <div class="card">
        <h2>üõ†Ô∏è Agent Configuration</h2>

        <div style="margin-bottom: 10px;">
            <label>Language:</label>
            <select id="languageSelector">
                <option value="en-US">English (US)</option>
                <option value="hi-IN">Hindi (India)</option>
                <option value="es-ES">Spanish (Spain)</option>
                <option value="fr-FR">French (France)</option>
                <option value="de-DE">German (Germany)</option>
            </select>
        </div>

        <label>System Prompt:</label>
        <textarea
            id="systemPrompt">You are a helpful voice assistant. Answer strictly based on the provided context if available. Keep answers concise. Respond in the same language as the user.</textarea>
        <button id="updatePromptBtn">Update Behavior</button>
    </div>

    <!-- Live Interaction -->
    <div class="card">
        <h2>üí¨ Live Transcript & Logs</h2>
        <div id="partialTranscript" style="color: #666; font-style: italic; margin-bottom: 10px; min-height: 1.2em;">
        </div>
        <div id="log"></div>
    </div>

    <!-- RAG Sources -->
    <div class="card" id="ragSourcesCard" style="display: none;">
        <h2>üîç Knowledge Retrieval (RAG)</h2>
        <div id="sourcesPanel" style="font-size: 0.85em; color: #444;"></div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/livekit-client/dist/livekit-client.umd.min.js"></script>
    <script>
        // DOM Elements
        const logDiv = document.getElementById('log');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const uploadBtn = document.getElementById('uploadBtn');
        const uploadInput = document.getElementById('kbUpload');
        const promptInput = document.getElementById('systemPrompt');
        const updatePromptBtn = document.getElementById('updatePromptBtn');
        const languageSelector = document.getElementById('languageSelector');

        // State
        let room, ws, audioContext;
        let isConnected = false;
        const audioQueue = [];
        let isPlaying = false;

        // --- UI Helpers ---
        function log(msg, source = "System") {
            const time = new Date().toLocaleTimeString();
            logDiv.innerHTML += `<div>[${time}] <b>${source}:</b> ${msg}</div>`;
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        function updateSourcesPanel(sources) {
            const card = document.getElementById('ragSourcesCard');
            const panel = document.getElementById('sourcesPanel');
            if (!sources || sources.length === 0) {
                card.style.display = 'none';
                return;
            }
            card.style.display = 'block';
            panel.innerHTML = sources.map(s => `
                <div style="margin-bottom: 8px; border-left: 3px solid #007bff; padding-left: 10px;">
                    <b>Source: ${s.source}</b><br/>
                    <i>"${s.text}"</i>
                </div>
            `).join('');
        }

        // --- Audio Playback (TTS) ---
        let currentSource = null; // Track current source to stop it

        async function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }
            isPlaying = true;
            const audioData = audioQueue.shift();

            try {
                // Ensure context is running
                if (audioContext.state === 'suspended') await audioContext.resume();

                // Decode & Play
                const buffer = await audioContext.decodeAudioData(audioData);
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(audioContext.destination);
                source.onended = playNextAudio;
                source.start(0);
                currentSource = source; // Save reference
            } catch (e) {
                console.error("Audio Playback Error:", e);
                playNextAudio();
            }
        }

        // --- WebSocket Setup ---
        function setupWebSocket(mediaStreamTrack) {
            ws = new WebSocket("ws://localhost:3000");
            ws.binaryType = "arraybuffer";

            ws.onopen = () => {
                log("Connected to Backend", "WS");

                // Sync initial prompt
                ws.send(JSON.stringify({ type: "update_prompt", prompt: promptInput.value }));
                startAudioCapture(mediaStreamTrack);
            };

            ws.onmessage = async (event) => {
                if (event.data instanceof ArrayBuffer) {
                    audioQueue.push(event.data);
                    if (!isPlaying) playNextAudio();
                } else {
                    const data = JSON.parse(event.data);

                    // Handle Interruption
                    if (data.type === "interrupt") {
                        // log("üõë Interrupted by User", "System");
                        audioQueue.length = 0; // Clear queue
                        if (currentSource) {
                            currentSource.stop();
                            currentSource = null;
                        }
                        isPlaying = false;
                        return;
                    }

                    if (data.type === "transcript") {
                        if (data.isFinal) {
                            // Clear partial and log final
                            document.getElementById('partialTranscript').innerText = "";
                            log(data.text, "You");
                        } else {
                            // Update live partial view
                            document.getElementById('partialTranscript').innerText = data.text + "...";
                        }
                    } else if (data.type === "agent_text") {
                        log(data.text, "Agent");
                    } else if (data.type === "rag_sources") {
                        updateSourcesPanel(data.sources);
                    }
                }
            };

            ws.onclose = () => log("Disconnected from Backend", "WS");
        }

        // --- Audio Capture (Worklet) ---
        async function startAudioCapture(track) {
            try {
                // Initialize AudioContext without forcing sampleRate (uses native, e.g. 48000)
                audioContext = new AudioContext(); // e.g. 48000Hz or 44100Hz
                await audioContext.resume();

                log(`Mic Sample Rate: ${audioContext.sampleRate}Hz`, "System");

                // Send Config to Backend
                ws.send(JSON.stringify({
                    type: "config",
                    sampleRate: audioContext.sampleRate,
                    language: languageSelector.value
                }));

                await audioContext.audioWorklet.addModule('/processor.js');

                const source = audioContext.createMediaStreamSource(new MediaStream([track]));
                const worklet = new AudioWorkletNode(audioContext, 'pcm-processor');

                source.connect(worklet);

                let chunkCount = 0;
                let audioBuffer = [];
                const CHUNKS_PER_SEND = 40; // ~100ms at 48kHz

                worklet.port.onmessage = (e) => {
                    audioBuffer.push(e.data);

                    if (audioBuffer.length >= CHUNKS_PER_SEND) {
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            // Combine chunks into one Int16Array
                            const combined = new Int16Array(audioBuffer.length * audioBuffer[0].length);
                            let offset = 0;
                            for (const chunk of audioBuffer) {
                                combined.set(chunk, offset);
                                offset += chunk.length;
                            }
                            ws.send(combined.buffer);
                            chunkCount++;
                        } else {
                            if (chunkCount % 10 === 0) console.warn("Audio skipped: WebSocket not open");
                            chunkCount++;
                        }
                        audioBuffer = []; // Reset
                    }
                };
            } catch (err) {
                log("Audio Pipeline Error: " + err.message, "Error");
            }
        }

        // --- Event Listeners ---
        connectBtn.onclick = async () => {
            connectBtn.disabled = true;
            log("Connecting to LiveKit...", "System");

            try {
                // 1. Get Token
                const identity = "user-" + Math.floor(Math.random() * 1000);
                const tokenRes = await fetch(`http://localhost:3000/getToken?identity=${identity}&roomName=demo-room`);
                const { token } = await tokenRes.json();

                // 2. Connect LiveKit
                room = new LivekitClient.Room();
                await room.connect('wss://assesment-56xzmjy9.livekit.cloud', token);
                await room.localParticipant.setMicrophoneEnabled(true);

                // 3. Get Mic Track & Start Pipeline
                const track = Array.from(room.localParticipant.trackPublications.values())
                    .find(p => p.kind === 'audio')?.track?.mediaStreamTrack;

                if (track) {
                    setupWebSocket(track);
                } else {
                    log("Microphone track not found!", "Error");
                }

                // UI Update
                isConnected = true;
                document.getElementById('connectionStatus').innerText = "Connected";
                document.getElementById('connectionStatus').classList.add("connected");
                disconnectBtn.disabled = false;
                log("Voice Session Active", "System");

            } catch (e) {
                log("Connection Failed: " + e.message, "Error");
                connectBtn.disabled = false;
            }
        };

        disconnectBtn.onclick = () => {
            if (room) room.disconnect();
            if (ws) ws.close();
            if (audioContext) audioContext.close();

            isConnected = false;
            connectBtn.disabled = false;
            disconnectBtn.disabled = true;
            document.getElementById('connectionStatus').innerText = "Disconnected";
            document.getElementById('connectionStatus').classList.remove("connected");
        };

        // KB Upload
        uploadInput.onchange = () => uploadBtn.disabled = !uploadInput.files[0];

        uploadBtn.onclick = async () => {
            const file = uploadInput.files[0];
            if (!file) return;

            const formData = new FormData();
            formData.append("file", file);

            try {
                uploadBtn.disabled = true;
                uploadBtn.innerText = "Ingesting...";
                log(`Uploading ${file.name}...`, "RAG");

                const res = await fetch("http://localhost:3000/upload-kb", {
                    method: "POST",
                    body: formData
                });

                if (res.ok) {
                    log(`${file.name} ingested successfully`, "RAG");
                    document.getElementById('uploadStatus').innerText = "‚úÖ Indexed";
                } else {
                    throw new Error("Upload failed");
                }
            } catch (e) {
                log("Upload Error", "Error");
            } finally {
                uploadBtn.disabled = false;
                uploadBtn.innerText = "Ingest Document";
            }
        };

        // Prompt Update
        updatePromptBtn.onclick = () => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: "update_prompt",
                    prompt: promptInput.value
                }));
                log("System Behavior Updated", "System");
            } else {
                log("Connect first to update prompt", "Error");
            }
        };
    </script>
</body>

</html>